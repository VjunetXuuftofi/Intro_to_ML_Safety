# ML for Improved Decision-Making
**Contributor(s): Nathaniel Li**

Today we celebrate not destroying the world. We do so today because 38 years ago, Stanislav Petrov made a decision that averted tremendous calamity. It's possible that an all-out nuclear exchange between the US and USSR would not have actually destroyed the world, but there are few things with an equal chance of doing so.

    As a Lieutenant Colonel of the Soviet Army, Petrov manned the system built to detect whether the US government had fired nuclear weapons on Russia. On September 26th, 1983, the system reported five incoming missiles. Petrovâ€™s job was to report this as an attack to his superiors, who would launch a retaliative nuclear response. But instead, contrary to the evidence the systems were giving him, he called it in as a false alarm, for he did not wish to instigate nuclear armageddon. 

## Background
This lecture discusses the applications of machine learning to improve institutional decision-making. Human judgement is not always perfect, particularly in moments of crisis or disagreement. Thus, we aim to improve the decision-making of institutions and leaders to reduce the risk of harmful decisions, by employing ML systems, which could have more objective, calibrated, and accurate judgements. Unlike other topics in this course, this note explores topics which can be applied to solve issues outside of AI safety. For example, these advancements can be applied to improve decision-making in international relations, conflict de-escalation, or pandemic response, contributing to increased *systemic safety*.

An example of this is the 

Within AI safety, 